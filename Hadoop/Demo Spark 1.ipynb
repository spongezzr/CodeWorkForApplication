{"cells":[{"cell_type":"markdown","source":["### Demo Spark 1\n\nIn this demo, let's find all the movies with the lowest average rating. \n\nIn the Data section of Databricks, upload the 2 files u.data and u.item if not done already. \nNote the path were the files have been saved in DBFS (e.g. \"dbfs:/FileStore/tables/q52fkb8t1508007409762/u.item\" or \"dbfs:/FileStore/tables/u.item\") and udpdate the code below.\n\nRefer to the Introduction to Databricks notebook for more details about the Spark functions used in this notebook."],"metadata":{}},{"cell_type":"code","source":["#List the path of the u.item and u.data\n\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/tables/\"))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Load u.item data\nrawItem = sc.textFile(\"<FILL IN WITH U.ITEM PATH IN DBFS>/u.item\")\n\n# Load u.data data\nrawData = sc.textFile(\"<FILL IN WITH U.DATA PATH IN DBFS>/u.data\")\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# rawItem records are populated like this:\n# movie_id|title|release_date|imbd_link| ... and other flag we won't need\n# 1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n# The \"|\" means the data are pipe (|) delimited\nrawItem.take(5)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# rawItem records are populated like this:\n# user_id \\t movie_id \\t rating \\t timestamp\n# 196\\t242\\t3\\t881250949\n# The \"\\t\" means the data are tab-delimited\nrawData.take(5)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Map rawItem data to (movie_id, title)\nmovieList = rawItem.map(lambda line: line.split(\"|\")).map(lambda x: (int(x[0]), x[1]))\n\n# Map our rawData to (movie_id, (rating, 1.0))\nmovieRatings = rawData.map(lambda line: line.split(\"\\t\")).map(lambda x: (int(x[1]), (int(x[2]), 1.0)))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Our movieList RDD has now the following structure: (movie_id, title)\n# It is a list of Tuples\nmovieList.take(5)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Our movieRatings RDD has now the following structure: (movie_id, (rating, 1.0))\n#It is a list of Tuples as well, with the second element of the Tuple being a Tuple itself: (rating, 1.0)\n#1.0 has been artificially added for aggregating/count purposes in the next steps.\nmovieRatings.take(5)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#Reduce to (movie_id (sumOfRatings, totalRatings))\n# The reduceByKey takes the first field of (movie_id, (rating, 1.0)) as the key, movie_id in this case. \n# The Lambda function of reduceByKey takes 2 arguments: movie1 and movie2. \n# movie1 and movie2 are records sharing the same key, so we are defining how we are combining records with same movie_id\n# movie1 and movie2 are the second part of the Tuple: (movie_id (rating, 1.0)) (remember movie_id is our key used by the reduceByKey), so movie1 and movie2 are of the form: (rating, 1.0)\n# To access rating and 1.0 separetely, we use the notation movie1[0] (for rating) and movie1[1] (for 1.0). Same applies to movie2.\n# Since here we want the sum of all ratings and the total number of ratings, we can just sum up movie1[0]+movie2[0] and movie1[1]+movie2[1]), which gives the following line of code:\nratingTotalsAndCount = movieRatings.reduceByKey(lambda movie1, movie2 : (movie1[0]+movie2[0], movie1[1]+movie2[1]))\n\n\n#Map to (movieID, AverageRating)\n# Since we have a Tuple of the form (movie_id (sumOfRatings, totalRatings)), we can easily get the average rating per movie_id:\naverageRatings = ratingTotalsAndCount.mapValues(lambda totalAndCount: totalAndCount[0] / totalAndCount[1])\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Sort by average Rating\n# We have now a Tuple of the form: (movie_id, AverageRating), we can sort by AverageRating or x[1] if x is our input for the Lambda function, x[0] being the movie_id:\nsortedMovies = averageRatings.sortBy(lambda x: x[1])\n\n#Join with movieList \n# We can join our averageRatings RDD with the movieList RDD using JOIN.\n# When called on RDDs of type (K, V) and (K, W), JOIN returns a dataset of (K, (V, W)) pairs with all pairs of elements for each key.\n# averageRatings has the form: (movie_id, AverageRating) and movieList has the form: (movie_id, title)\njoinRDD = averageRatings.join(movieList)\n\n#joinRDD has the form: (movie_id,(AverageRating, title))\njoinRDD.take(5)\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Keep title and average rating only\n# joinRDD has the form: (movie_id,(AverageRating, title)), x[1] returns the Tuple (AverageRating, title) if x is the input of the Lambda function. \nlistSorted = joinRDD.map(lambda x: (x[1]))\n\n#Sort by average Rating\n# listSorted has the form: (AverageRating, title), we can sort by AverageRating.\nresults = listSorted.sortBy(lambda x: x[0])\nresults.collect()\n"],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"name":"Demo Spark 1","notebookId":3732822489043753},"nbformat":4,"nbformat_minor":0}
